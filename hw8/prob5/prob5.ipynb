{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "from ipywidgets import interactive\n",
                "import ipywidgets as widgets\n",
                "from ipywidgets import fixed\n",
                "from mpl_toolkits.mplot3d import Axes3D\n",
                "\n",
                "def generate_x_widget(name, value):\n",
                "    return widgets.FloatSlider(\n",
                "        value=value,\n",
                "        min=0.,\n",
                "        max=1.,\n",
                "        step=0.01,\n",
                "        description=name + ': ',\n",
                "        continuous_update= False)\n",
                "def generate_y_widget(name):\n",
                "    return widgets.FloatSlider(\n",
                "        value=0.5,\n",
                "        min=0.,\n",
                "        max=1.,\n",
                "        step=0.01,\n",
                "        description=name + ': ',\n",
                "        continuous_update= False)\n",
                "def generate_w_coord_widget(name):\n",
                "    return widgets.FloatSlider(\n",
                "        value=0,\n",
                "        min=-1.,\n",
                "        max=1.,\n",
                "        step=0.02,\n",
                "        description=name + ': ',\n",
                "        continuous_update= False)\n",
                "def generate_iter_num_widget(max_iter):\n",
                "    return widgets.IntSlider(\n",
                "        value=max_iter//10,\n",
                "        min=0,\n",
                "        max=max_iter-1,\n",
                "        step=2,\n",
                "        description='iteration: ',\n",
                "        disabled=False,\n",
                "        continuous_update=False,\n",
                "        orientation='horizontal',\n",
                "        readout=True,\n",
                "        readout_format='d')\n",
                "\n",
                "def generate_parametrization_choice_widget():\n",
                "    return  widgets.Dropdown(\n",
                "        options=['usual', 'nn'],\n",
                "        description='parametrization: ',\n",
                "        disabled=False\n",
                "    )\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Introduction\n",
                "\n",
                "In this notebook we will deal with a toy example of learning overparametrized model with SGD: we will learn a quadratic function on $[0,1]$ from only two samples. The choice of this problem is due to visualization capabilities: we can plot in at most 3 dimensions, so we need at most 3 model parameters. On the other hand, we need at least 2 samples for SGD to be meaningful.\n",
                "\n",
                "\n",
                "\n",
                "We are going to compare the following two parametrizations of quadratic functions:\n",
                "\\begin{align*}\n",
                "\\{w_0x^2 + w_1x + w_2\\}_{{\\bf w} \\in \\mathbb{R}^3}\\text{ and }\\{w_1(w_0x +1)^2 + w_2\\}_{{\\bf w} \\in \\mathbb{R}^3}\n",
                "\\end{align*}\n",
                "in terms of interaction with SGD. The first one corresponds to our usual polynomial features regression, and the second one is more like a \"neural net style\" parametrization.\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Part 1\n",
                "\n",
                "So we consider quadratic functions with two parametrizations:\n",
                "$$\n",
                "q_{usual}({\\bf w}, x) := w_0x^2 + w_1x + w_2\n",
                "$$\n",
                "and\n",
                "$$\n",
                "q_{nn}({\\bf w}, x) := w_1(w_0x +1)^2 + w_2.\n",
                "$$\n",
                "\n",
                "In the next cell you will implement the functions that compute the corresponding stochastic gradients. Each of those functions takes 3 inputs: $x_{train} \\in \\mathbb{R}$, $y_{train} \\in \\mathbb{R}$ and ${\\bf w} = [w_0, w_1, w_2] \\in \\mathbb{R}^3$. The output should be\n",
                "$$\n",
                "\\nabla_{{\\bf w}}\\left(\\frac12 (q\\left({\\bf w}, x_{train}) - y_{train}\\right)^2\\right),\n",
                "$$\n",
                "where $q = q_{usual}$ for the first function, and $q = q_{nn}$ for the second.\n",
                "\n",
                "**Implement the functions in the cell below.**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def usual_parametrization_grad(x_train, y_train, w):\n",
                "    ### start usual_grad ###\n",
                "\n",
                "    ### end usual_grad ###\n",
                "\n",
                "def nn_parametrization_grad(x_train, y_train, w):\n",
                "    ### start nn_grad ###\n",
                "\n",
                "    ### end nn_grad ###\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Part 2\n",
                "\n",
                "In this part we are going to see how SGD interacts with both parametrizations. The following cell gives an implementation of SGD. You don't need to write any code here, just **run the next cell**.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def SGD(one_sample_grad, step_size, n_iter, X_train, y_train, w_initial):\n",
                "\n",
                "    w_current = np.copy(w_initial)\n",
                "    trajectory = [np.copy(w_current)]\n",
                "    point_indices = np.random.randint(low=0, high=len(y_train), size=n_iter)\n",
                "\n",
                "    for iter_num in range(n_iter):\n",
                "        current_pt_index = point_indices[iter_num]\n",
                "        w_current -= step_size * one_sample_grad(X_train[current_pt_index], y_train[current_pt_index], w_current)\n",
                "        trajectory.append(np.copy(w_current))\n",
                "\n",
                "    return trajectory\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "In the next cell we run SGD for both parametrizations for 3000 steps. We initialize weights at zero and set the step size to be constant $0.05$. After that we visualize the learned functions for different iterations.\n",
                "\n",
                "**Run the following cell. For each parametrization report after how many iterations SGD converged to the interpolating solution.**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%matplotlib inline\n",
                "\n",
                "X_train = [0.3, 0.7]\n",
                "y_train = [0.09, 0.49]\n",
                "n_iter = 3000\n",
                "w_initial=np.zeros(3)\n",
                "step_size = 0.05\n",
                "\n",
                "usual_traj = SGD(one_sample_grad=usual_parametrization_grad,\n",
                "               step_size=step_size,\n",
                "               n_iter=n_iter,\n",
                "               X_train=X_train,\n",
                "               y_train=y_train,\n",
                "               w_initial=w_initial)\n",
                "\n",
                "nn_traj = SGD(one_sample_grad=nn_parametrization_grad,\n",
                "               step_size=step_size,\n",
                "               n_iter=n_iter,\n",
                "               X_train=X_train,\n",
                "               y_train=y_train,\n",
                "               w_initial=w_initial)\n",
                "\n",
                "def plot_iterations(iter_num):\n",
                "    usual_res = usual_traj[iter_num]\n",
                "    nn_res = nn_traj[iter_num]\n",
                "    x_test = np.linspace(0,1,100)\n",
                "    plt.close()\n",
                "    plt.plot(x_test, usual_res[0] * x_test**2 + usual_res[1] * x_test + usual_res[2], label='usual')\n",
                "    plt.plot(x_test, nn_res[1] *(nn_res[0] * x_test + 1)**2 + nn_res[2], label='nn style')\n",
                "    plt.scatter(X_train, y_train, label='training points')\n",
                "    plt.legend()\n",
                "    plt.show()\n",
                "\n",
                "interactive_plot = interactive(plot_iterations,\n",
                "                               iter_num=generate_iter_num_widget(n_iter))\n",
                "interactive_plot\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Part 3\n",
                "\n",
                "Now we visualize the training process in the weight space. Run the next cel to see how weights change during the SGD. You can choose the parametrization and the initial weights. The 3d plot should be interactive (you should be able to rotate it with your mouse). Darker points correspond to earlier iterations.\n",
                "\n",
                "- **Explain how you can visually observe the result of part b of the problem by looking at the trajectory for the usual parametrization.**\n",
                "- **Do you observe anything analogous for the \"neural network\" style parametrization?**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Here we call %matplotlib notebook several times because sometimes it doesn't work as expected on the first try.\n",
                "#If the output of this cell doesn't look right, try rerunning it\n",
                "%matplotlib notebook\n",
                "%matplotlib notebook\n",
                "%matplotlib notebook\n",
                "%matplotlib notebook\n",
                "%matplotlib notebook\n",
                "%matplotlib notebook\n",
                "\n",
                "def plot_training_trajectory(parametrization, w_0, w_1, w_2):\n",
                "    if parametrization == 'nn':\n",
                "        one_sample_grad=nn_parametrization_grad\n",
                "    else:\n",
                "        one_sample_grad=usual_parametrization_grad\n",
                "    traj = SGD(one_sample_grad=one_sample_grad,\n",
                "                   step_size=step_size,\n",
                "                   n_iter=n_iter,\n",
                "                   X_train=X_train,\n",
                "                   y_train=y_train,\n",
                "                   w_initial=np.array([w_0, w_1, w_2]))\n",
                "\n",
                "    traj = np.array(traj)\n",
                "    fig = plt.figure()\n",
                "    ax = fig.add_subplot(111, projection='3d')\n",
                "    ax.scatter(traj[:, 0], traj[:,1], traj[:,2], c=np.linspace(0,10, len(traj))**0.2)\n",
                "    plt.show()\n",
                "\n",
                "interactive_plot = interactive(plot_training_trajectory,\n",
                "                           parametrization=generate_parametrization_choice_widget(),\n",
                "                              w_0=generate_w_coord_widget('$w_0$'),\n",
                "                              w_1=generate_w_coord_widget('$w_1$'),\n",
                "                              w_2=generate_w_coord_widget('$w_2$'))\n",
                "interactive_plot\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Part 4\n",
                "\n",
                "Finally, we compare the learned functions that we obtain from two parametrizations. The next cell lets you choose the training data and runs SGD for both parametrizations for 3000 steps.\n",
                "- **Observe that SGD doesn't always converge to the interpolating solution. What values of the training data seem to be the hardest for convergence? For which parametrization is it harder to converge?**\n",
                "- **Now restrict yourself only to regimes where the SGD converges. How would you describe the difference between the learned functions?**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%matplotlib inline\n",
                "\n",
                "\n",
                "n_iter = 3000\n",
                "w_initial=np.zeros(3)\n",
                "step_size = 0.05\n",
                "\n",
                "def plot_learned_functions(x_train_1, x_train_2, y_train_1, y_train_2 ):\n",
                "    X_train = np.array([x_train_1, x_train_2])\n",
                "    y_train = np.array([y_train_1, y_train_2])\n",
                "    usual_traj = SGD(one_sample_grad=usual_parametrization_grad,\n",
                "                   step_size=step_size,\n",
                "                   n_iter=n_iter,\n",
                "                   X_train=X_train,\n",
                "                   y_train=y_train,\n",
                "                   w_initial=w_initial)\n",
                "\n",
                "    nn_traj = SGD(one_sample_grad=nn_parametrization_grad,\n",
                "                   step_size=step_size,\n",
                "                   n_iter=n_iter,\n",
                "                   X_train=X_train,\n",
                "                   y_train=y_train,\n",
                "                   w_initial=w_initial)\n",
                "\n",
                "\n",
                "    usual_res = usual_traj[n_iter]\n",
                "    nn_res = nn_traj[n_iter]\n",
                "    x_test = np.linspace(0,1,100)\n",
                "    plt.close()\n",
                "    plt.ylim(-0.1, 1.1)\n",
                "    plt.plot(x_test, usual_res[0] * x_test**2 + usual_res[1] * x_test + usual_res[2], label='usual')\n",
                "    plt.plot(x_test, nn_res[1] *(nn_res[0] * x_test + 1)**2 + nn_res[2], label='nn style')\n",
                "    plt.scatter(X_train, y_train, label='training points')\n",
                "    plt.legend()\n",
                "    plt.show()\n",
                "\n",
                "interactive_plot = interactive(plot_learned_functions,\n",
                "                               x_train_1=generate_x_widget('$x_1$', 0.3),\n",
                "                               x_train_2=generate_x_widget('$x_2$', 0.7),\n",
                "                               y_train_1=generate_y_widget('$y_1$'),\n",
                "                               y_train_2=generate_y_widget('$y_2$'))\n",
                "interactive_plot\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.7.4"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}