{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# [HW10] Problem: Linear Methods on Fruits and Veggies\n",
                "\n",
                "Import necessary Python packages.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "from scipy.stats import norm\n",
                "from numpy.random import uniform\n",
                "from numpy.random import randn\n",
                "import random\n",
                "import time\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "from scipy.linalg import eig\n",
                "from scipy.linalg import sqrtm\n",
                "from numpy.linalg import inv\n",
                "from numpy.linalg import svd\n",
                "\n",
                "from utils import create_one_hot_label\n",
                "from utils import subtract_mean_from_data\n",
                "from utils import compute_covariance_matrix\n",
                "\n",
                "import numpy as np\n",
                "import numpy.linalg as LA\n",
                "\n",
                "import sys\n",
                "from numpy.linalg import svd\n",
                "import matplotlib.image as mpimg\n",
                "import matplotlib.pyplot as plt\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Visualize the image\n",
                "\n",
                "**To start with this problem, we first take a look at a figure of banana in the dataset.**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from IPython.display import Image\n",
                "Image(filename='banana.png', width = 260, height = 260)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Then we random shuffle the pixels in the above image.**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Read Images\n",
                "img = mpimg.imread('banana.png')\n",
                "rdmImg = np.reshape(img, (img.shape[0] * img.shape[1], img.shape[2]))\n",
                "# shuffle\n",
                "np.random.shuffle(rdmImg)\n",
                "# reshape to original shape\n",
                "rdmImg = np.reshape(rdmImg, img.shape)\n",
                "\n",
                "plt.imshow(rdmImg)\n",
                "plt.show()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Let us visulize an image of an apple.**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "Image(filename='apple.png', width = 260, height = 260)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Read Images\n",
                "img = mpimg.imread('apple.png')\n",
                "rdmImg = np.reshape(img, (img.shape[0] * img.shape[1], img.shape[2]))\n",
                "# shuffle\n",
                "np.random.shuffle(rdmImg)\n",
                "# reshape to original shape\n",
                "rdmImg = np.reshape(rdmImg, img.shape)\n",
                "\n",
                "plt.imshow(rdmImg)\n",
                "plt.show()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**The above two images are exactly the same in terms of the HSV colorspace histogram feature.**\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Part (a). Random Projection.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from projection import Projections, Project2D\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "X = list(np.load('little_x_train.npy'))\n",
                "Y = list(np.load('little_y_train.npy'))\n",
                "\n",
                "CLASS_LABELS = ['apple', 'banana', 'eggplant']\n",
                "\n",
                "feat_dim = max(X[0].shape)\n",
                "projections = Projections(feat_dim, CLASS_LABELS)\n",
                "\n",
                "rand_proj = projections.get_random_proj()\n",
                "# Show Random 2D Projection\n",
                "proj2D_viz = Project2D(rand_proj, CLASS_LABELS)\n",
                "proj2D_viz.project_data(X, Y, white=np.eye(feat_dim), title='random projection')\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Part (b). PCA Projection.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "X = list(np.load('little_x_train.npy'))\n",
                "Y = list(np.load('little_y_train.npy'))\n",
                "\n",
                "CLASS_LABELS = ['apple', 'banana', 'eggplant']\n",
                "\n",
                "feat_dim = max(X[0].shape)\n",
                "projections = Projections(feat_dim, CLASS_LABELS)\n",
                "\n",
                "# PCA Projection\n",
                "pca_proj = projections.pca_projection(X, Y)\n",
                "\n",
                "# Show PCA 2D Projection\n",
                "proj2D_viz = Project2D(pca_proj, CLASS_LABELS)\n",
                "proj2D_viz.project_data(X, Y, white=np.eye(feat_dim), title='PCA projection')\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Part (c). CCA Projection.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "X = list(np.load('little_x_train.npy'))\n",
                "Y = list(np.load('little_y_train.npy'))\n",
                "\n",
                "CLASS_LABELS = ['apple', 'banana', 'eggplant']\n",
                "\n",
                "feat_dim = max(X[0].shape)\n",
                "projections = Projections(feat_dim, CLASS_LABELS)\n",
                "\n",
                "# CCA Projection\n",
                "cca_proj, white_cov = projections.cca_projection(X, Y)\n",
                "# Show CCA 2D Projection\n",
                "proj2D_viz = Project2D(cca_proj, CLASS_LABELS)\n",
                "proj2D_viz.project_data(X, Y, white=white_cov, title='CCA projection')\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Before we start the following parts, we first import several functions.**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from projection import Project2D, Projections\n",
                "from confusion_mat import getConfusionMatrixPlot\n",
                "\n",
                "from ridge_model import Ridge_Model\n",
                "from svm_model import SVM_Model\n",
                "from logistic_model import Logistic_Model\n",
                "from linear_classification import Model\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Part (d). Ridge Regression.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load Training Data and Labels\n",
                "X = list(np.load('little_x_train.npy'))\n",
                "Y = list(np.load('little_y_train.npy'))\n",
                "\n",
                "# Load Validation Data and Labels\n",
                "X_val = list(np.load('little_x_val.npy'))\n",
                "Y_val = list(np.load('little_y_val.npy'))\n",
                "\n",
                "CLASS_LABELS = ['apple', 'banana', 'eggplant']\n",
                "\n",
                "# Project Data to 200 Dimensions using CCA\n",
                "feat_dim = max(X[0].shape)\n",
                "projections = Projections(feat_dim, CLASS_LABELS)\n",
                "cca_proj, white_cov = projections.cca_projection(X, Y, k=200)\n",
                "\n",
                "X = projections.project(cca_proj, white_cov, X)\n",
                "X_val = projections.project(cca_proj, white_cov, X_val)\n",
                "\n",
                "\n",
                "#####RUN RIDGE REGRESSION#####\n",
                "ridge_m = Ridge_Model(CLASS_LABELS)\n",
                "model = Model(ridge_m)\n",
                "\n",
                "model.train_model(X, Y)\n",
                "model.test_model(X, Y)\n",
                "model.test_model(X_val, Y_val)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Part (e). LDA (Linear Discriminant Analysis).\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import numpy.linalg as LA\n",
                "\n",
                "import sys\n",
                "from numpy.linalg import inv\n",
                "from numpy.linalg import det\n",
                "from sklearn.svm import LinearSVC\n",
                "from projection import Project2D, Projections\n",
                "\n",
                "\n",
                "class LDA_Model():\n",
                "    def __init__(self,class_labels):\n",
                "        self.lmbda = 0.001\n",
                "        self.NUM_CLASSES = len(class_labels)\n",
                "    def compute_class_means(self,X,Y):\n",
                "        class_data = {}\n",
                "        for i in range(len(X)):\n",
                "            x = X[i]\n",
                "            y = Y[i]\n",
                "            if str(y) in class_data:\n",
                "                class_data[str(y)].append(x)\n",
                "            else:\n",
                "                class_data[str(y)] = [x]\n",
                "        self.class_means = {}\n",
                "\n",
                "        for cls in class_data.keys():\n",
                "            data = class_data[cls]\n",
                "            data = np.array(data)\n",
                "            mu = np.mean(data,0)\n",
                "            self.class_means[cls] = mu\n",
                "\n",
                "    def compute_class_cov(self,X,Y):\n",
                "        N = len(X)\n",
                "        x_dim = np.max(X[0].shape)\n",
                "        C = np.zeros([x_dim,x_dim], dtype=float)\n",
                "\n",
                "        # Calculate matrix C\n",
                "        ### TODO: The code you need to fill is for calculating the covariance\n",
                "        ###       matrix C for LDA.\n",
                "        ### You need adding regularization in C (i.e., 0.001*np.eye(C.shape[0])).\n",
                "        ### start code ###\n",
                "\n",
                "        ### end code ###\n",
                "\n",
                "        self.inv_cov =  inv(C)\n",
                "\n",
                "\n",
                "    def train_model(self,X,Y):\n",
                "        self.compute_class_means(X,Y)\n",
                "        self.compute_class_cov(X,Y)\n",
                "\n",
                "\n",
                "    def compute_likelihood(self,clss,x):\n",
                "        inv_cov = self.inv_cov\n",
                "        mean = self.class_means[clss]\n",
                "        prod_term = -1*np.matmul((x-mean).T,np.matmul(inv_cov,(x-mean)))\n",
                "\n",
                "        return prod_term\n",
                "\n",
                "\n",
                "\n",
                "    def eval(self,x):\n",
                "        prediction = np.zeros(self.NUM_CLASSES)\n",
                "        i = 0\n",
                "        for i in range(self.NUM_CLASSES):\n",
                "            prediction[i] = self.compute_likelihood(str(i),x)\n",
                "            i = i+1\n",
                "        return np.argmax(prediction)\n",
                "\n",
                "    def evals(self, X):\n",
                "        # X has shape n*d\n",
                "        X = np.array(X)\n",
                "        N = X.shape[0]\n",
                "        D = X.shape[1]\n",
                "        C = self.NUM_CLASSES\n",
                "        prediction = np.zeros((N, C))\n",
                "\n",
                "        for i in range(C):\n",
                "            mmean = X - np.reshape(self.class_means[str(i)], (1, -1))\n",
                "            prediction[:, i] = -1 * np.ravel(np.reshape(mmean, (N, 1, D)) @ self.inv_cov @ np.reshape(mmean, (N, D, 1)))\n",
                "        return np.argmax(prediction, axis=1)\n",
                "\n",
                "\n",
                "#####RUN LDA REGRESSION#####\n",
                "\n",
                "lda_m = LDA_Model(CLASS_LABELS)\n",
                "model = Model(lda_m)\n",
                "\n",
                "model.train_model(X, Y)\n",
                "model.test_model(X, Y)\n",
                "model.test_model(X_val, Y_val)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Part (f). QDA (Quadratic Discriminant Analysis).\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class QDA_Model():\n",
                "\n",
                "    def __init__(self, class_labels):\n",
                "\n",
                "        self.lmbda = 0.001\n",
                "        self.NUM_CLASSES = len(class_labels)\n",
                "\n",
                "    def compute_class_means(self, X, Y):\n",
                "\n",
                "        self.class_data = {}\n",
                "\n",
                "        for i in range(len(X)):\n",
                "\n",
                "            x = X[i]\n",
                "            y = Y[i]\n",
                "\n",
                "            if str(y) in self.class_data:\n",
                "                self.class_data[str(y)].append(x)\n",
                "            else:\n",
                "                self.class_data[str(y)] = [x]\n",
                "\n",
                "        self.class_means = {}\n",
                "\n",
                "        for cls in self.class_data.keys():\n",
                "            data = self.class_data[cls]\n",
                "\n",
                "            data_n = np.array(data)\n",
                "            mu = np.mean(data_n, 0)\n",
                "\n",
                "            self.class_means[cls] = mu\n",
                "\n",
                "    def compute_class_cov(self, X, Y):\n",
                "\n",
                "        N = len(X)\n",
                "\n",
                "        x_dim = np.max(X[0].shape)\n",
                "\n",
                "        self.class_inv_cov = {}\n",
                "        self.class_cov = {}\n",
                "\n",
                "        for cls in self.class_data.keys():\n",
                "            C = np.zeros([x_dim, x_dim], dtype=float)\n",
                "            data = self.class_data[cls]\n",
                "            mu = self.class_means[cls]\n",
                "            N = len(data)\n",
                "\n",
                "            # Calculate matrix C\n",
                "            ### TODO: The code you need to fill is for calculating the covariance\n",
                "            ###       matrix C for QDA.\n",
                "            ### You need adding regularization in each C (i.e., 0.001*np.eye(C.shape[0])).\n",
                "            ### start code ###\n",
                "\n",
                "            ### end code ###\n",
                "\n",
                "\n",
                "            self.class_inv_cov[cls] = inv(C)\n",
                "            self.class_cov[cls] = np.copy(C)\n",
                "\n",
                "    def train_model(self, X, Y):\n",
                "\n",
                "        self.compute_class_means(X, Y)\n",
                "        self.compute_class_cov(X, Y)\n",
                "\n",
                "    def compute_likelihood(self, clss, x):\n",
                "\n",
                "        cov = self.class_cov[clss]\n",
                "        inv_cov = self.class_inv_cov[clss]\n",
                "        mean = self.class_means[clss]\n",
                "        prod_term = -np.log(det(cov)) - np.matmul((x - mean).T, np.matmul(inv_cov, (x - mean)))\n",
                "\n",
                "        return prod_term\n",
                "\n",
                "    def eval(self, x):\n",
                "\n",
                "        prediction = np.zeros(self.NUM_CLASSES)\n",
                "        i = 0\n",
                "        for i in range(self.NUM_CLASSES):\n",
                "            prediction[i] = self.compute_likelihood(str(i), x)\n",
                "            i = i + 1\n",
                "\n",
                "        return np.argmax(prediction)\n",
                "\n",
                "\n",
                "#####RUN QDA REGRESSION#####\n",
                "\n",
                "qda_m = QDA_Model(CLASS_LABELS)\n",
                "model = Model(qda_m)\n",
                "\n",
                "model.train_model(X, Y)\n",
                "model.test_model(X, Y)\n",
                "model.test_model(X_val, Y_val)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Part (g). Linear SVM.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#####RUN SVM REGRESSION#####\n",
                "\n",
                "svm_m = SVM_Model(CLASS_LABELS)\n",
                "model = Model(svm_m)\n",
                "\n",
                "model.train_model(X, Y)\n",
                "model.test_model(X, Y)\n",
                "model.test_model(X_val, Y_val)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Part (h). Logistic Regression\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#####RUN Logistic REGRESSION#####\n",
                "lr_m = Logistic_Model(CLASS_LABELS)\n",
                "model = Model(lr_m)\n",
                "\n",
                "model.train_model(X, Y)\n",
                "model.test_model(X, Y)\n",
                "model.test_model(X_val, Y_val)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Part (i)-(j). ROC (Receiver Operating Characteristic).\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "CLASS_LABELS = ['apple', 'banana']\n",
                "\n",
                "\n",
                "def compute_tp_fp(thres, scores, labels):\n",
                "    scores = np.array(scores)\n",
                "    prediction = (scores > thres)\n",
                "    tp = np.sum(prediction * labels)\n",
                "    tpr = 1.0 * tp / np.sum(labels)\n",
                "\n",
                "    fp = np.sum(prediction * (1 - labels))\n",
                "    fpr = 1.0 * fp / np.sum(1 - labels)\n",
                "    return tpr, fpr\n",
                "\n",
                "\n",
                "def plot_ROC(tps, fps):\n",
                "    # plot\n",
                "    plt.plot(fps, tps)\n",
                "    plt.ylabel(\"True Positive Rates\")\n",
                "    plt.xlabel(\"False Positive Rates\")\n",
                "\n",
                "\n",
                "def ROC(scores, labels):\n",
                "    thresholds = sorted(np.unique(scores))\n",
                "    thresholds = [-float(\"Inf\")] + thresholds + [float(\"Inf\")]\n",
                "    tps = []\n",
                "    fps = []\n",
                "\n",
                "    ### TODO: The code you need to fill in is to apply the 'compute_tp_fp' function to\n",
                "    ###       compute the true positive rate (TPR) and false positive rate (FPR),\n",
                "    ###       and add the calculated tpr and fpr to the lists: tps and fps.\n",
                "    ### start code ###\n",
                "\n",
                "    ### end code ###\n",
                "\n",
                "    return tps, fps\n",
                "\n",
                "def eval_with_ROC(method, train_X, train_Y, val_X, val_Y, C, change_score=False):\n",
                "    m = method(CLASS_LABELS)\n",
                "    m.C = C\n",
                "    m.train_model(train_X, train_Y)\n",
                "    scores = m.scores(val_X)\n",
                "    #### change the scores here\n",
                "    if change_score:\n",
                "        scores = 10.0 * np.array(scores)\n",
                "\n",
                "    tps, fps = ROC(scores, val_Y)\n",
                "    plot_ROC(tps, fps)\n",
                "\n",
                "def trim_data(X, Y):\n",
                "    # throw away the 3rd class data\n",
                "    X = np.array(X)\n",
                "    Y = np.array(Y)\n",
                "    retain = (Y < 2)\n",
                "    return X[retain, :], Y[retain]\n",
                "\n",
                "\n",
                "# Load Training Data and Labels\n",
                "X = list(np.load('little_x_train.npy'))\n",
                "Y = list(np.load('little_y_train.npy'))\n",
                "X, Y = trim_data(X, Y)\n",
                "\n",
                "# Load Validation Data and Labels\n",
                "X_val = list(np.load('little_x_val.npy'))\n",
                "Y_val = list(np.load('little_y_val.npy'))\n",
                "X_val, Y_val = trim_data(X_val, Y_val)\n",
                "\n",
                "CLASS_LABELS = ['apple', 'banana']\n",
                "\n",
                "# Project Data to 200 Dimensions using CCA\n",
                "feat_dim = max(X[0].shape)\n",
                "projections = Projections(feat_dim, CLASS_LABELS)\n",
                "cca_proj, white_cov = projections.cca_projection(X, Y, k=200)\n",
                "X = projections.project(cca_proj, white_cov, X)\n",
                "X_val = projections.project(cca_proj, white_cov, X_val)\n",
                "\n",
                "##### RUN SVM REGRESSION #####\n",
                "eval_with_ROC(SVM_Model, X, Y, X_val, Y_val, 1.0)\n",
                "eval_with_ROC(SVM_Model, X, Y, X_val, Y_val, 0.01)\n",
                "plt.legend([\"C=1.0\", \"C=0.01\"])\n",
                "plt.show()\n",
                "\n",
                "##### RUN SVM REGRESSION (after changing score) #####\n",
                "eval_with_ROC(SVM_Model, X, Y, X_val, Y_val, 1.0, change_score=True)\n",
                "eval_with_ROC(SVM_Model, X, Y, X_val, Y_val, 1.0, change_score=False)\n",
                "plt.legend([\"C=0.01\", \"C=0.01 (multiply the scores)\"])\n",
                "plt.show()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Part (k). Hyperparameters Search.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from confusion_mat import getConfusionMatrix\n",
                "from confusion_mat import plotConfusionMatrix\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "CLASS_LABELS = ['apple', 'banana', 'nectarine', 'plum', 'peach', 'watermelon', 'pear', 'mango', 'grape', 'orange',\n",
                "                'strawberry', 'pineapple',\n",
                "                'radish', 'carrot', 'potato', 'tomato', 'bellpepper', 'broccoli', 'cabbage', 'cauliflower', 'celery',\n",
                "                'eggplant', 'garlic', 'spinach', 'ginger']\n",
                "\n",
                "\n",
                "def eval_model(X, Y, k, model_key, proj):\n",
                "    # PROJECT DATA\n",
                "    cca_proj, white_cov = proj.cca_projection(X, Y, k=k)\n",
                "\n",
                "    X_p = proj.project(cca_proj, white_cov, X)\n",
                "    X_val_p = proj.project(cca_proj, white_cov, X_val)\n",
                "\n",
                "    # TRAIN MODEL\n",
                "    model = models[model_key]\n",
                "\n",
                "    model.train_model(X_p, Y)\n",
                "    acc, cm = model.test_model(X_val_p, Y_val)\n",
                "\n",
                "    return acc, cm\n",
                "\n",
                "\n",
                "class Model():\n",
                "    \"\"\" Generic wrapper for specific model instance. \"\"\"\n",
                "\n",
                "    def __init__(self, model):\n",
                "        \"\"\" Store specific pre-initialized model instance. \"\"\"\n",
                "\n",
                "        self.model = model\n",
                "\n",
                "    def train_model(self, X, Y):\n",
                "        \"\"\" Train using specific model's training function. \"\"\"\n",
                "\n",
                "        self.model.train_model(X, Y)\n",
                "\n",
                "    def test_model(self, X, Y):\n",
                "        \"\"\" Test using specific model's eval function. \"\"\"\n",
                "        if hasattr(self.model, \"evals\"):\n",
                "            labels = np.array(Y)\n",
                "            p_labels = self.model.evals(X)\n",
                "            success = np.sum(labels == p_labels)\n",
                "            total_count = len(X)\n",
                "\n",
                "        else:\n",
                "            labels = []  # List of actual labels\n",
                "            p_labels = []  # List of model's predictions\n",
                "            success = 0  # Number of correct predictions\n",
                "            total_count = 0  # Number of images\n",
                "\n",
                "            for i in range(len(X)):\n",
                "\n",
                "                x = X[i]  # Test input\n",
                "                y = Y[i]  # Actual label\n",
                "                y_ = self.model.eval(x)  # Model's prediction\n",
                "                labels.append(y)\n",
                "                p_labels.append(y_)\n",
                "\n",
                "                if y == y_:\n",
                "                    success += 1\n",
                "                total_count += 1\n",
                "\n",
                "        return 1.0 * success / total_count, getConfusionMatrix(labels, p_labels)\n",
                "\n",
                "\n",
                "\n",
                "\n",
                "# Load Training Data and Labels\n",
                "X = list(np.load('big_x_train.npy'))\n",
                "Y = list(np.load('big_y_train.npy'))\n",
                "\n",
                "# Load Validation Data and Labels\n",
                "X_val = list(np.load('big_x_val.npy'))\n",
                "Y_val = list(np.load('big_y_val.npy'))\n",
                "\n",
                "# Project Data to 200 Dimensions using CCA\n",
                "feat_dim = max(X[0].shape)\n",
                "projections = Projections(feat_dim, CLASS_LABELS)\n",
                "\n",
                "models = {}  # Dictionary of key: model names, value: model instance\n",
                "\n",
                "#########MODELS TO EVALUATE############\n",
                "qda_m = QDA_Model(CLASS_LABELS)\n",
                "models['qda'] = Model(qda_m)\n",
                "\n",
                "lda_m = LDA_Model(CLASS_LABELS)\n",
                "models['lda'] = Model(lda_m)\n",
                "\n",
                "ridge_m = Ridge_Model(CLASS_LABELS)\n",
                "models['ridge'] = Model(ridge_m)\n",
                "\n",
                "ridge_m_10 = Ridge_Model(CLASS_LABELS)\n",
                "ridge_m_10.lmbda = 10.0\n",
                "models['ridge_lmda_10'] = Model(ridge_m_10)\n",
                "\n",
                "ridge_m_01 = Ridge_Model(CLASS_LABELS)\n",
                "ridge_m_01.lmbda = 0.1\n",
                "models['ridge_lmda_01'] = Model(ridge_m_01)\n",
                "\n",
                "# svm_m = SVM_Model(CLASS_LABELS)\n",
                "# models['svm'] = Model(svm_m)\n",
                "\n",
                "svm_m_01 = SVM_Model(CLASS_LABELS)\n",
                "svm_m_01.C = 0.1\n",
                "models['svm_C_01'] = Model(svm_m_01)\n",
                "\n",
                "svm_m_001 = SVM_Model(CLASS_LABELS)\n",
                "svm_m_001.C = 0.01\n",
                "models['svm_C_001'] = Model(svm_m_001)\n",
                "\n",
                "#########GRID SEARCH OVER MODELS############\n",
                "highest_accuracy = 0  # Highest validation accuracy\n",
                "best_model_name = None  # Best model name\n",
                "best_model = None  # Best model instance\n",
                "best_k = None\n",
                "\n",
                "K = [20, 25, 30, 50, 100]  # List of dimensions\n",
                "\n",
                "for model_key in models.keys():\n",
                "    print(model_key)\n",
                "\n",
                "    val_acc = []  # List of model's accuracies for each dimension\n",
                "    for k in K:\n",
                "        print(\"k =\", k)\n",
                "\n",
                "        # Evaluate specific model's validation accuracy on specific dimension\n",
                "        acc, c_m = eval_model(X, Y, k, model_key, projections)\n",
                "\n",
                "        val_acc.append(acc)\n",
                "\n",
                "        if acc > highest_accuracy:\n",
                "            highest_accuracy = acc\n",
                "            best_model_name = model_key\n",
                "            best_cm = c_m\n",
                "            best_k = k\n",
                "\n",
                "    # Plot specific model's accuracies across validation error\n",
                "    plt.plot(K, val_acc, label=model_key)\n",
                "\n",
                "# Display aggregate plot of models across validation error\n",
                "plt.legend()\n",
                "plt.xlabel('Dimension')\n",
                "plt.ylabel('Accuracy')\n",
                "plt.show()\n",
                "\n",
                "# Plot best model's confusion matrix\n",
                "plotConfusionMatrix(best_cm, CLASS_LABELS)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print('best model: ', best_model_name)\n",
                "print('best k: ', best_k)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**You could try higher dimensions for CCA, also could try to use larger $C$ in SVM, but it may take more than one hour to run the above hyper parameter search part.**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}